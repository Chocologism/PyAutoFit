{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 2: Dataset Sample\n",
        "==========================\n",
        "\n",
        "In this tutorial, we'll fit a multiple `Dataset`s with the same phase, producing multiple sets of results on our\n",
        "hard-disk. In the following tutorials, we then use these results and the `Aggregator` to load the results into\n",
        "our Jupyter notebook to interpret, inspect and plot the output results.\n",
        "\n",
        "we'll fit 3 different `Dataset`s, each with a single `Gaussian` model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from howtofit.chapter_2_results import src as htf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the configs as we did in the previous tutorial, as well as the output folder for our `NonLinearSearch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\",\n",
        "    output_path=f\"{workspace_path}/output/chapter_2\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, for each `Dataset` we are going to set up the correct path, load it, create its `mask` and fit it using a `Phase`.\n",
        "\n",
        "We want our results to be in a folder specific to the `Dataset`. we'll use the `Dataset`'s name string to do this. Lets\n",
        "create a list of all 3 of our `Dataset` names.\n",
        "\n",
        "we'll also pass these names to the `Dataset` when we create it, the name will be used by the `Aggregator` to name the \n",
        "file the data is stored. More importantly, the name will be accessible to the `Aggregator`, and we will use it to label \n",
        "figures we make via the `Aggregator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_2 import (\n",
        "    gaussian_x1_0,\n",
        "    gaussian_x1_1,\n",
        "    gaussian_x1_2,\n",
        ")\n",
        "\n",
        "dataset_names = [\"gaussian_x1_0\", \"gaussian_x1_1\", \"gaussian_x1_2\"]\n",
        "datas = [gaussian_x1_0.data, gaussian_x1_1.data, gaussian_x1_2.data]\n",
        "noise_maps = [gaussian_x1_0.noise_map, gaussian_x1_1.noise_map, gaussian_x1_2.noise_map]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also attach information to the model-fit, by setting up an info dictionary. \n",
        "\n",
        "Information about our model-fit (e.g. the data of observation) that isn't part of the model-fit is made accessible to \n",
        "the `Aggregator`. For example, below we write info on the `Dataset`'s data of observation and exposure time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "info = {\"date_of_observation\": \"01-02-18\", \"exposure_time\": 1000.0}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This for loop runs over every `Dataset`, checkout the comments below for how we set up the path structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for index in range(len(datas)):\n",
        "\n",
        "    \"\"\"The code below creates the `Dataset` and `mask` as per usual.\"\"\"\n",
        "\n",
        "    dataset = htf.Dataset(data=datas[index], noise_map=noise_maps[index])\n",
        "\n",
        "    mask = np.full(fill_value=False, shape=dataset.data.shape)\n",
        "\n",
        "    \"\"\"\n",
        "    Here, we create a `Phase` as normal. However, we also include an input parameter `folders`. This defines the \n",
        "    names of any folders that the `Phase` outputs results to. For example, if a `Phase` outputs to the path:\n",
        "\n",
        "        `/path/to/autofit_workspace/output/phase_name/`\n",
        "\n",
        "    A `Phase` with the input `folders=[`phase_folder`]` edits this path to:\n",
        "\n",
        "        `/path/to/autofit_workspace/output/phase_folder/phase_name/`\n",
        "\n",
        "    You can input multiple `phase folders`, for example `folders=[`folder_0`, `folder_1`]` would create the path:\n",
        "\n",
        "        `/path/to/autofit_workspace/output/folder_0/folder_1/phase_name/`\n",
        "\n",
        "    Below, we use the `data_name`, so our results go in a folder specific to the `Dataset`, e.g:\n",
        "\n",
        "        `/path/to/autofit_workspace/output/gaussian_x1_0/phase_t2/`\n",
        "    \"\"\"\n",
        "\n",
        "    print(\n",
        "        f\"Emcee has begun running - checkout the \"\n",
        "        f\"autofit_workspace/howtofit/chapter_2_results/output/aggregator/{dataset_names[index]}/phase_t2 folder for live \"\n",
        "        f\"output of the results. This Jupyter notebook cell with progress once Emcee has completed - this could take a \"\n",
        "        f\"few minutes!\"\n",
        "    )\n",
        "\n",
        "    phase = htf.Phase(\n",
        "        phase_name=\"phase_t2_agg\",\n",
        "        folders=[\"aggregator\", dataset_names[index]],\n",
        "        profiles=af.CollectionPriorModel(gaussian=htf.profiles.Gaussian),\n",
        "        settings=htf.SettingsPhase(),\n",
        "        search=af.DynestyStatic(),\n",
        "    )\n",
        "\n",
        "    \"\"\"Note that we pass the info to the `phase` when we run it, so that the `Aggregator` can make it accessible.\"\"\"\n",
        "\n",
        "    phase.run(dataset=dataset, mask=mask, info=info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout the output folder - you should see three new sets of results corresponding to our 3 `Gaussian` datasets.\n",
        "\n",
        "Unlike previous tutorials, these folders in the output folder are named after the `Dataset` and contain the folder\n",
        "with the phase`s name, as opposed to just the phase-name folder."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}