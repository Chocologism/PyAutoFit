{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 2: Dataset Sample\n",
        "==========================\n",
        "\n",
        "In this tutorial, we'll fit a multiple datasets with the same phase, producing multiple sets of results on our\n",
        "hard-disk. In the following tutorials, we then use these results and the _Aggregator_ to load the results into\n",
        "our Jupyter notebook to interpret, inspect and plot the output results.\n",
        "\n",
        "We'll fit 3 different dataset's, each with a single _Gaussian_ model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from howtofit.chapter_2_results import src as htf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the configs as we did in the previous tutorial, as well as the output folder for our non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\",\n",
        "    output_path=f\"{workspace_path}/output/chapter_2\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, for each _Dataset_ we are going to set up the correct path, load it, create its mask and fit it using a phase.\n",
        "\n",
        "We want our results to be in a folder specific to the _Dataset_. We'll use the _Dataset_'s name string to do this. Lets\n",
        "create a list of all 3 of our _Dataset_ names.\n",
        "\n",
        "We'll also pass these names to the _Dataset_ when we create it - the name will be used by the _Aggregator_ to name the \n",
        "file the data is stored. More importantly, the name will be accessible to the aggregator, and we will use it to label \n",
        "figures we make via the aggregator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_2 import (\n",
        "    gaussian_x1_0,\n",
        "    gaussian_x1_1,\n",
        "    gaussian_x1_2,\n",
        ")\n",
        "\n",
        "dataset_names = [\"gaussian_x1_0\", \"gaussian_x1_1\", \"gaussian_x1_2\"]\n",
        "datas = [gaussian_x1_0.data, gaussian_x1_1.data, gaussian_x1_2.data]\n",
        "noise_maps = [gaussian_x1_0.noise_map, gaussian_x1_1.noise_map, gaussian_x1_2.noise_map]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also attach information to the model-fit, by setting up an info dictionary. \n",
        "\n",
        "Information about our model-fit (e.g. the data of osbervation) that isn't part of the model-fit is made accessible to \n",
        "the _Aggregator_. For example, below we write info on the _Dataset_'s data of observation and exposure time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "info = {\"date_of_observation\": \"01-02-18\", \"exposure_time\": 1000.0}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This for loop runs over every _Dataset_, checkout the comments below for how we set up the path structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for index in range(len(datas)):\n",
        "\n",
        "    \"\"\"The code below creates the _Dataset_ and mask as per usual.\"\"\"\n",
        "\n",
        "    dataset = htf.Dataset(data=datas[index], noise_map=noise_maps[index])\n",
        "\n",
        "    mask = np.full(fill_value=False, shape=dataset.data.shape)\n",
        "\n",
        "    \"\"\"\n",
        "    Here, we create a phase as normal. However, we also include an input parameter 'folders'. The phase folders\n",
        "    define the names of folders that the phase goes in. For example, if a phase goes to the path:\n",
        "\n",
        "        '/path/to/autofit_workspace/output/phase_name/'\n",
        "\n",
        "    A phase folder with the input 'phase_folder' edits this path to:\n",
        "\n",
        "        '/path/to/autofit_workspace/output/phase_folder/phase_name/'\n",
        "\n",
        "    You can input multiple phase folders, for example 'folders=['folder_0', 'folder_1'] would create the path:\n",
        "\n",
        "        '/path/to/autofit_workspace/output/folder_0/folder_1/phase_name/'\n",
        "\n",
        "    Below, we use the data_name, so our results go in a folder specific to the _Dataset_, e.g:\n",
        "\n",
        "        '/path/to/autofit_workspace/output/gaussian_x1_0/phase_t2/'\n",
        "    \"\"\"\n",
        "\n",
        "    print(\n",
        "        f\"Emcee has begun running - checkout the \"\n",
        "        f\"autofit_workspace/howtofit/chapter_2_results/output/aggregator/{dataset_names[index]}/phase_t2 folder for live \"\n",
        "        f\"output of the results. This Jupyter notebook cell with progress once Emcee has completed - this could take a \"\n",
        "        f\"few minutes!\"\n",
        "    )\n",
        "\n",
        "    phase = htf.Phase(\n",
        "        phase_name=\"phase_t2_agg\",\n",
        "        folders=[\"aggregator\", dataset_names[index]],\n",
        "        profiles=af.CollectionPriorModel(gaussian=htf.profiles.Gaussian),\n",
        "        settings=htf.SettingsPhase(),\n",
        "        search=af.DynestyStatic(),\n",
        "    )\n",
        "\n",
        "    \"\"\"Note that we pass the info to the phase when we run it, so that the aggregator can make it accessible.\"\"\"\n",
        "\n",
        "    phase.run(dataset=dataset, mask=mask, info=info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout the output folder - you should see three new sets of results corresponding to our 3 _Gaussian_ datasets.\n",
        "\n",
        "Unlike previous tutorials, these folders in the output folder are named after the _Dataset_ and contain the folder\n",
        "with the phase's name, as opposed to just the phase-name folder."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}