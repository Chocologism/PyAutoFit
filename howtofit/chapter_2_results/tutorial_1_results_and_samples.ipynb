{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 1: Results\n",
        "===================\n",
        "\n",
        "In this tutorial, we'll cover all of the output that comes from a `Phase` in the form of a `Result` object.\n",
        "\n",
        "We'll use the same problem of fitting 1D profiles to noisy data, with the source code we use to do this in chapter 2\n",
        "an adaption of the source code we completed chapter 1 using. It has new funtionality which we'll cover throughout this\n",
        "chapter, but for this tutorial the source code is use as we used it before.\n",
        "\n",
        "We used this object at various points in the previous chapter, and the bulk of material covered here is described in\n",
        "the example script 'autofit_workspace/examples/simple/result.py'. Nevertheless, it is a good idea to refresh ourselves\n",
        "about how results in **PyAutoFit** work before covering more advanced material."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from howtofit.chapter_2_results import src as htf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the configs as we did in the previous tutorial, as well as the output folder for our non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\",\n",
        "    output_path=f\"{workspace_path}/output/chapter_2\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, lets create a `Dataset` and fit it using a `Phase`, in an identical fashion to the previous chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_2 import gaussian_x1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we fit the data-sets, we will omit the data-trimming demonstrated in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_masked_dataset = htf.SettingsMaskedDataset(\n",
        "    data_trim_left=None, data_trim_right=None\n",
        ")\n",
        "\n",
        "settings = htf.SettingsPhase(settings_masked_dataset=settings_masked_dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code below creates the `Dataset` and mask as per usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = gaussian_x1.data\n",
        "noise_map = gaussian_x1.noise_map\n",
        "dataset = htf.Dataset(data=data, noise_map=noise_map)\n",
        "mask = np.full(fill_value=False, shape=dataset.data.shape)\n",
        "\n",
        "print(\n",
        "    f\"Emcee has begun running - checkout the \"\n",
        "    f\"autofit_workspace/howtofit/chapter_2_results/output/phase_t1 folder for live \"\n",
        "    f\"output of the results. This Jupyter notebook cell with progress once Emcee has completed - this could take a \"\n",
        "    f\"few minutes!\"\n",
        ")\n",
        "\n",
        "phase = htf.Phase(\n",
        "    phase_name=\"phase_t1\",\n",
        "    profiles=af.CollectionPriorModel(gaussian=htf.profiles.Gaussian),\n",
        "    settings=settings,\n",
        "    search=af.DynestyStatic(),\n",
        ")\n",
        "\n",
        "\"\"\"Note that we pass the info to the phase when we run it, so that the aggregator can make it accessible.\"\"\"\n",
        "result = phase.run(dataset=dataset, mask=mask)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Here, we'll look in detail at what information is contained in the result.\n",
        "\n",
        "It contains a *Samples* object, which contains information on the non-linear sampling, for example the parameters. \n",
        "\n",
        "The parameters are stored as a a list of lists, where:\n",
        "\n",
        " - The outer list is the size of the total number of samples.\n",
        " - The inner list is the size of the number of free parameters in the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "print(\"All Parameters:\")\n",
        "print(samples.parameters)\n",
        "print(\"Sample 10's third parameter value (Gaussian -> sigma)\")\n",
        "print(samples.parameters[9][1], \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` class also contains the log likelihood, log prior, log posterior and weights of every accepted sample, \n",
        "where:\n",
        "\n",
        " - The log likelihood is the value evaluated from the likelihood function (e.g. -0.5 * chi_squared + the noise \n",
        " normalized).\n",
        "\n",
        " - The log prior encodes information on how the priors on the parameters maps the log likelihood value to the log\n",
        " posterior value.\n",
        "\n",
        " - The log posterior is log_likelihood + log_prior.\n",
        "\n",
        " - The weight gives information on how samples should be combined to estimate the posterior. The weight values \n",
        " depend on the sampler used, for MCMC samples they are all 1 (e.g. all weighted equally)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"All Log Likelihoods:\")\n",
        "print(samples.log_likelihoods)\n",
        "print(\"All Log Priors:\")\n",
        "print(samples.log_priors)\n",
        "print(\"All Log Posteriors:\")\n",
        "print(samples.log_posteriors)\n",
        "print(\"All Sample Weights:\")\n",
        "print(samples.weights, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The samples contain many useful vectors, including the samples with the highest likelihood and posterior values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_log_likelihood_vector = samples.max_log_likelihood_vector\n",
        "max_log_posterior_vector = samples.max_log_posterior_vector\n",
        "\n",
        "print(\"Maximum Log Likelihood Vector:\")\n",
        "print(max_log_likelihood_vector)\n",
        "print(\"Maximum Log Posterior Vector:\")\n",
        "print(max_log_posterior_vector, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This provides us with lists of all model parameters. However, this isn't that much use - which values correspond to \n",
        "which parameters?\n",
        "\n",
        "The list of parameter names are available as a property of the  `Samples` , as are parameter labels which can be used \n",
        "for labeling figures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(samples.parameter_names)\n",
        "print(samples.parameter_labels)\n",
        "print(\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is more useful to return the `Result`'s as an instance, which is an instance of the model using the Python classes \n",
        "used to compose it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_log_likelihood_instance = samples.max_log_likelihood_instance"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A model instance contains all the model components of our fit - which for the fit above was a single gaussian\n",
        "profile (the word 'gaussian' comes from what we called it in the CollectionPriorModel when making the phase above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(max_log_likelihood_instance.profiles.gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can unpack the parameters of the `Gaussian` to reveal the maximum log likelihood parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Max Log Likelihood `Gaussian` Instance:\")\n",
        "print(\"Centre = \", max_log_likelihood_instance.profiles.gaussian.centre)\n",
        "print(\"Intensity = \", max_log_likelihood_instance.profiles.gaussian.intensity)\n",
        "print(\"Sigma = \", max_log_likelihood_instance.profiles.gaussian.sigma, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our example problem of fitting a 1D `Gaussian` profile, this makes it straight forward to plot the maximum\n",
        "likelihood model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_data = samples.max_log_likelihood_instance.profiles.gaussian.profile_from_xvalues(\n",
        "    xvalues=np.arange(data.shape[0])\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(data.shape[0]), data)\n",
        "plt.plot(range(data.shape[0]), model_data)\n",
        "plt.title(\"Illustrative model fit to 1D `Gaussian` profile data.\")\n",
        "plt.xlabel(\"x values of profile\")\n",
        "plt.ylabel(\"Profile intensity\")\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the 'median pdf' model, which is the model computed by marginalizing over the samples of every \n",
        "parameter in 1D and taking the median of this PDF.\n",
        "\n",
        "The median pdf vector is readily available from the *Samples* object for you convenience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "median_pdf_vector = samples.median_pdf_vector\n",
        "print(\"Median PDF Vector:\")\n",
        "print(median_pdf_vector, \"\\n\")\n",
        "\n",
        "median_pdf_instance = samples.median_pdf_instance\n",
        "print(\"Median PDF `Gaussian` Instance:\")\n",
        "print(\"Centre = \", median_pdf_instance.profiles.gaussian.centre)\n",
        "print(\"Intensity = \", median_pdf_instance.profiles.gaussian.intensity)\n",
        "print(\"Sigma = \", median_pdf_instance.profiles.gaussian.sigma, \"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` class also provides methods for computing the error estimates of all parameters at an input sigma \n",
        "confidence limit, which can be returned at the values of the parameters including their errors or the size of the \n",
        "errors on each parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vector_at_upper_sigma = samples.vector_at_upper_sigma(sigma=3.0)\n",
        "vector_at_lower_sigma = samples.vector_at_lower_sigma(sigma=3.0)\n",
        "\n",
        "print(\"Upper Parameter values w/ error (at 3.0 sigma confidence):\")\n",
        "print(vector_at_upper_sigma)\n",
        "print(\"lower Parameter values w/ errors (at 3.0 sigma confidence):\")\n",
        "print(vector_at_lower_sigma, \"\\n\")\n",
        "\n",
        "error_vector_at_upper_sigma = samples.error_vector_at_upper_sigma(sigma=3.0)\n",
        "error_vector_at_lower_sigma = samples.error_vector_at_lower_sigma(sigma=3.0)\n",
        "\n",
        "print(\"Upper Error values (at 3.0 sigma confidence):\")\n",
        "print(error_vector_at_upper_sigma)\n",
        "print(\"lower Error values (at 3.0 sigma confidence):\")\n",
        "print(error_vector_at_lower_sigma, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All methods above are available as an instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance_at_upper_sigma = samples.instance_at_upper_sigma\n",
        "instance_at_lower_sigma = samples.instance_at_lower_sigma\n",
        "error_instance_at_upper_sigma = samples.error_instance_at_upper_sigma\n",
        "error_instance_at_lower_sigma = samples.error_instance_at_lower_sigma"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An instance of any accepted sample can be created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = samples.instance_from_sample_index(sample_index=500)\n",
        "print(\"Gaussian Instance of sample 5000:\")\n",
        "print(\"Centre = \", instance.profiles.gaussian.centre)\n",
        "print(\"Intensity = \", instance.profiles.gaussian.intensity)\n",
        "print(\"Sigma = \", instance.profiles.gaussian.sigma, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because `DynestyStatic`, a nested sampling *non-linear search* was used, the evidence of the model is also available \n",
        "which enables Bayesian model comparison to be performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_evidence = samples.log_evidence"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, lets remind ourselves of the `Result` class in the module:\n",
        "\n",
        " 'chapter_2_results/src/phase/result.py' \n",
        " \n",
        "Here, we extended the `Result` class with two additional methods:\n",
        "\n",
        " - max_log_likelihood_model_data\n",
        " - max_log_likelihood_fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "htf.plot.Line.line(xvalues=dataset.xvalues, line=result.max_log_likelihood_model_data)\n",
        "htf.plot.FitDataset.chi_squared_map(fit=result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Probability Density Functions (PDF's) of the results can be plotted using the library:\n",
        "\n",
        " corner.py: https://corner.readthedocs.io/en/latest/\n",
        "\n",
        "(In built visualization for PDF's and non-linear searches is a future feature of PyAutoFit, but for now you'll have to \n",
        "use the libraries yourself!).\n",
        "\"\"\"\n",
        "\n",
        "import corner\n",
        "\n",
        "corner.corner(xs=samples.parameters, weights=samples.weights)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}