{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af\n",
        "from howtofit.chapter_1_introduction.tutorial_7_phase_customization.src.dataset.dataset import (\n",
        "    Dataset,\n",
        ")\n",
        "from howtofit.chapter_1_introduction.tutorial_7_phase_customization.src.phase.result import (\n",
        "    Result,\n",
        ")\n",
        "from howtofit.chapter_1_introduction.tutorial_7_phase_customization.src.phase.analysis import (\n",
        "    Analysis,\n",
        ")\n",
        "from howtofit.chapter_1_introduction.tutorial_7_phase_customization.src.phase.meta_dataset import (\n",
        "    MetaDataset,\n",
        ")\n",
        "from howtofit.chapter_1_introduction.tutorial_7_phase_customization.src.phase.settings import (\n",
        "    PhaseSettings,\n",
        ")\n",
        "\n",
        "\n",
        "# The phase module has new features not included in tutorial 6, which customize the dataset that is fitted and tag\n",
        "# the output path of the results.\n",
        "\n",
        "\n",
        "class Phase(af.AbstractPhase):\n",
        "\n",
        "    # Because we now have multiple profiles in our model, we have renamed 'gaussian' to 'profiles'. As before,\n",
        "    # PyAutoFit uses this information to map the input Profile classes to a model instance when performing a fit.\n",
        "\n",
        "    profiles = af.PhaseProperty(\"profiles\")\n",
        "\n",
        "    Result = Result\n",
        "\n",
        "    @af.convert_paths\n",
        "    def __init__(self, paths, profiles, settings, search):\n",
        "        \"\"\"\n",
        "        A phase which fits a model composed of multiple profiles (Gaussian, Exponential) using a non-linear search.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        paths : af.Paths\n",
        "            Handles the output directory structure.\n",
        "        profiles : [profiles.Profile]\n",
        "            The model components (e.g. Gaussian, Exponenial) fitted by this phase.\n",
        "        search: class\n",
        "            The class of a non_linear search\n",
        "        settings : PhaseSettings\n",
        "            The collection of settings of the phase used to augment the data that is fitted and tag the output path.\n",
        "        \"\"\"\n",
        "\n",
        "        # Here, we create a 'tag' for our phase. If we use an optional phase setting to alter the dataset we fit (here,\n",
        "        # a data_trim_ variable), we want to 'tag' the phase such that results are output to a unique\n",
        "        # directory whose names makes it explicit how the dataset was changed.\n",
        "\n",
        "        # If this setting is off, the tag is an empty string and thus the directory structure is not changed.\n",
        "\n",
        "        paths.tag = settings.tag  # The phase_tag must be manually added to the phase.\n",
        "\n",
        "        super().__init__(paths=paths, search=search)\n",
        "\n",
        "        self.profiles = profiles\n",
        "\n",
        "        # Phase settings alter the dataset that is fitted, however a phase does not have access to the dataset until it\n",
        "        # is run (e.g. the run method below is passed the dataset). In order for a phase to use its input phase\n",
        "        # settings to create the dataset it fits, these settings are stored in the 'meta_dataset' attribute and used\n",
        "        # when the 'run' and 'make_analysis' methods are called.\n",
        "\n",
        "        self.meta_dataset = MetaDataset(settings=settings)\n",
        "\n",
        "    def run(self, dataset: Dataset, mask):\n",
        "        \"\"\"\n",
        "        Pass a dataset to the phase, running the phase and non-linear search.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: aa.Dataset\n",
        "            The dataset fitted by the phase, as defined in the 'dataset.py' module.\n",
        "        mask: Mask\n",
        "            The mask used for the analysis.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        result: AbstractPhase.Result\n",
        "            A result object comprising information on the non-linear search and the maximum likelihood model.\n",
        "        \"\"\"\n",
        "\n",
        "        analysis = self.make_analysis(dataset=dataset, mask=mask)\n",
        "\n",
        "        result = self.run_analysis(analysis=analysis)\n",
        "\n",
        "        return self.make_result(result=result, analysis=analysis)\n",
        "\n",
        "    def make_analysis(self, dataset, mask):\n",
        "        \"\"\"\n",
        "        Create an Analysis object, which creates the dataset and contains the functions which perform the fit.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: aa.Dataset\n",
        "            The dataset fitted by the phase, as defined in the 'dataset.py' module.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        analysis : Analysis\n",
        "            An analysis object that the non-linear search calls to determine the fit log_likelihood for a given model\n",
        "            instance.\n",
        "        \"\"\"\n",
        "\n",
        "        # Here, the meta_dataset is used to create the masked dataset that is fitted. If the data_trim_left and / or\n",
        "        # data_trim_right settings are passed into the phase, the function below uses them to alter the masked dataset.\n",
        "\n",
        "        # Checkout 'meta_dataset.py' for more details.\n",
        "\n",
        "        masked_dataset = self.meta_dataset.masked_dataset_from_dataset_and_mask(\n",
        "            dataset=dataset, mask=mask\n",
        "        )\n",
        "\n",
        "        return Analysis(\n",
        "            masked_dataset=masked_dataset, image_path=self.search.paths.image_path\n",
        "        )\n",
        "\n",
        "    def make_result(self, result, analysis):\n",
        "        return self.Result(\n",
        "            samples=result.samples,\n",
        "            previous_model=self.model,\n",
        "            search=self.search,\n",
        "            analysis=analysis,\n",
        "        )\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}