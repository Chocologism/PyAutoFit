{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 5: Visualization & Masking\n",
        "===================================\n",
        "\n",
        "In the previous tutorial, we wrote source code which used **PyAutoFit** to fit a 1D `Gaussian` model to a `Dataset`.\n",
        "In this tutorial, we'll extend this source code`s phase package to perform a number of additional tasks:\n",
        "\n",
        " - Masking: The phase is passed a mask such that regions of the `Dataset` are omitted by the `log_likelihood_function`.\n",
        "\n",
        " - Visualization: Images showing the model fit are output on-the-fly during the `NonLinearSearch`.\n",
        "\n",
        "These new features have lead to an additional module in the `phase` package not present in tutorial 4, called\n",
        "`visualizer.py`. Before looking at this module, lets perform a fit to see the changed behaviour of **PyAutoFit**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "#%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autofit as af\n",
        "from autofit_workspace.howtofit.chapter_1_introduction.tutorial_5_visualization_masking import (\n",
        "    src as htf,\n",
        ")\n",
        "\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data and set up the `Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = \"dataset/howtofit/chapter_1/gaussian_x1\"\n",
        "data = af.util.numpy_array_from_json(file_path=f\"{dataset_path}/data.json\")\n",
        "noise_map = af.util.numpy_array_from_json(file_path=f\"{dataset_path}/noise_map.json\")\n",
        "\n",
        "dataset = htf.Dataset(data=data, noise_map=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before fitting data, we may want to mask it, removing regions of the data we know are defective or where there is no\n",
        "signal.\n",
        "\n",
        "To facilitate this we have added a new class to the module `dataset.py`. This takes our `Dataset` and a mask and \n",
        "combines the two to create a `MaskedDataset`. The `fit.py` module has also been updated to use a mask during the fit. \n",
        "Check them both out now to see how the mask is used! \n",
        "\n",
        "As mentioned in tutorial 4, if your model-fitting problem involves fitting masked data, you should be able to copy and \n",
        "paste the `fit.py` module for your own project.\n",
        "\n",
        "Masking occurs within the phase package of **PyAutoFit**, which we'll inspect at the end of the tutorial. However,\n",
        "for a phase to run it now requires that a `mask` is passed to it. For this tutorial, lets create a which removes the\n",
        "last 30 data-points in our `data`.\n",
        "\n",
        "(In our convention, a `mask` value of `True` means it IS masked and thus removed from the fit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = np.full(fill_value=False, shape=dataset.data.shape)\n",
        "mask[-30:] = True"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now perform the fit from tutorial 4, but with a `MaskedDataset` and visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase = htf.Phase(\n",
        "    search=af.Emcee(path_prefix=\"howtofit/chapter_1\", name=\"phase_t5\"),\n",
        "    gaussian=af.PriorModel(htf.Gaussian),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t4\"\n",
        "    \" folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that we are passing our `mask` to the `phase.run` function, which we did not in previous tutorials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets check that this phase performs visualization. Navigate to the folder `image` in the directory above. You should \n",
        "see a set of folders containing the visualization of the `Dataset` and the `Fit`. As promised, our phase is\n",
        "now taking care of the visualization of our model.\n",
        "\n",
        "Visualization happens `on-the-fly`, such that during `Emcee` these images are output using the current maximum \n",
        "likelihood model `Emcee` has found. For models more complex than our 1D `Gaussian` this is useful, as it means we can \n",
        "check that `Emcee` has found reasonable solutions during a run and can thus cancel it early if it has ended up with an\n",
        "incorrect solution.\n",
        "\n",
        "How often does **PyAutoFit** output new images? This is set by `visualize_every_update` in the config file\n",
        "`config/visualize/general.ini`.\n",
        "\n",
        "Finally, now inspect the `phase.py`, `analysis.py` and `visualizer.py` scripts in the source code. These describe how \n",
        "the `MaskedData` is set up and how visualization is performed.\n",
        "\n",
        "And with that, we have completed this (fairly short) tutorial. There are two things worth ending on:\n",
        "\n",
        " 1) In tutorial 4, we introduced the `plot` package that had functions specific to plotting attributes of\n",
        " a data-set and fit. This project structure has again helped us, by making it straight forward to perform plotting with \n",
        " the _Visualizer-. For your model-fitting project you should aim to adhere to performing all plots in a `plot` \n",
        " module, as more benefits will become clear in chapter 2!\n",
        "    \n",
        " 2) For our very simple 1D case, we used a 1D ndarray to represent a `mask`. For projects with more complicated\n",
        " datasets, one may require more complicated masks, warranting a `mask` package, `mask.py` module and `Mask2D` class. In \n",
        " tutorial 9 we will show an example of this."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}