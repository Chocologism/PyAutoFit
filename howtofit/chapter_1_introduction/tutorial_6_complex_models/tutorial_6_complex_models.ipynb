{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 6: Complex Models\n",
        "==========================\n",
        "\n",
        "Up to now, we've fitted a very simple model, a 1D `Gaussian` with 3 free parameters. In this tutorial, we'll look at\n",
        "how **PyAutoFit** allows us to compose and fit models of arbitrary complexity.\n",
        "\n",
        "To begin, you should check out the module `tutorial_6_complex_models/model/profiles.py`. In previous tutorials this\n",
        "module was called `gaussian.py` and contained only the `Gaussian` class. The module now includes a second profile,\n",
        "_Exponential_, which like the `Gaussian` class is a model-component that can be fitted to data.\n",
        "\n",
        "Up to now, our data has always been generated using a single `Gaussian` profile. Thus, we have only needed to fit\n",
        "it with a single `Gaussian`. In this tutorial, our `Dataset` is now a superpositions of multiple profiles. The models\n",
        "we compose and fit are therefore composed of multiple profiles, such that when we generate the model-data we\n",
        "generate it as the sum of all individual profiles in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from howtofit.chapter_1_introduction.tutorial_6_complex_models import (\n",
        "    src as htf,\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the configs as we did in the previous tutorial, as well as the output folder for our `NonLinearSearch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\",\n",
        "    output_path=f\"{workspace_path}/output/chapter_1\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets quickly recap tutorial 1, where using `PriorModels` we created a `Gaussian` as a model component and used it to \n",
        "map a list of parameters to a model `instance`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.PriorModel(htf.profiles.Gaussian)\n",
        "\n",
        "print(\"PriorModel `Gaussian` object: \\n\")\n",
        "print(model)\n",
        "\n",
        "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3])\n",
        "\n",
        "print(\"Model Instance: \\n\")\n",
        "print(instance)\n",
        "\n",
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x = \", instance.centre)\n",
        "print(\"intensity = \", instance.intensity)\n",
        "print(\"sigma = \", instance.sigma)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining a model using multiple model components is straight forward in **PyAutoFit**, using a _CollectionPriorModel_\n",
        "object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian=htf.profiles.Gaussian, exponential=htf.profiles.Exponential\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A `CollectionPriorModel` behaves like a `PriorModel` but contains a collection of model components. For example, it can\n",
        "create a model instance by mapping a list of parameters, which in this case is 6 (3 for the `Gaussian` `[centre,\n",
        "intensity, sigma]` and 3 for the `Exponential` `[centre, intensity, rate]`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This `instance` contains each of the model components we defined above, using the input argument name of the\n",
        "_CollectionoPriorModel_ to define the attributes in the `instance`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x (Gaussian) = \", instance.gaussian.centre)\n",
        "print(\"intensity (Gaussian) = \", instance.gaussian.intensity)\n",
        "print(\"sigma (Gaussian) = \", instance.gaussian.sigma)\n",
        "print(\"x (Exponential) = \", instance.exponential.centre)\n",
        "print(\"intensity (Exponential) = \", instance.exponential.intensity)\n",
        "print(\"sigma (Exponential) = \", instance.exponential.rate)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can call the components of a `CollectionPriorModel` whatever we want, and the mapped `instance` will use those names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_custom_names = af.CollectionPriorModel(\n",
        "    james=htf.profiles.Gaussian, rich=htf.profiles.Exponential\n",
        ")\n",
        "\n",
        "instance = model_custom_names.instance_from_vector(\n",
        "    vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01]\n",
        ")\n",
        "\n",
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x (Gaussian) = \", instance.james.centre)\n",
        "print(\"intensity (Gaussian) = \", instance.james.intensity)\n",
        "print(\"sigma (Gaussian) = \", instance.james.sigma)\n",
        "print(\"x (Exponential) = \", instance.rich.centre)\n",
        "print(\"intensity (Exponential) = \", instance.rich.intensity)\n",
        "print(\"sigma (Exponential) = \", instance.rich.rate)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create a model composed of multiple components, lets fit it to a `Dataset`. To do this, we updated this \n",
        "tutorial`s `phase` package, spefically its `Analysis` class such that it creates `model_data` as a super position of \n",
        "all the model`s individual `Profile`'s. For example, in the model above, the `model_data` is the sum of the \n",
        "_Gaussian_`s  individual profile and `Exponential`'s individual profile.\n",
        "\n",
        "Checkout `phase.py` and `analysis.py` now, for a description of how this has been implemented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the `simulators` module and set up the `Dataset`. This uses a new `Dataset` that is generated as a sum of a \n",
        "_Gaussian_ and `Exponential` profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_1 import gaussian_x1_exponential_x1\n",
        "\n",
        "dataset = htf.Dataset(\n",
        "    data=gaussian_x1_exponential_x1.data, noise_map=gaussian_x1_exponential_x1.noise_map\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again need to create a `mask` for our data which we pass to the `phase.run` method. In this example, our `mask` is\n",
        "only `False` entries meaning that every datapoint is used in the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = np.full(fill_value=False, shape=dataset.data.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now perform the fit using our model which is composed of two _Profile`_s. You`ll note that the _Emcee_\n",
        "dimensionality has increased from N=3 to N=6, given that we are now fitting two `Profile`'s each with 3 free parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase = htf.Phase(\n",
        "    phase_name=\"phase_t6_gaussian_x1_exponential_x1\",\n",
        "    profiles=af.CollectionPriorModel(\n",
        "        gaussian=htf.profiles.Gaussian, exponential=htf.profiles.Exponential\n",
        "    ),\n",
        "    search=af.Emcee(),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x1_exponential_x1\"\n",
        "    \" folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quickly inspect the `Result`'s of the fit, which you may have noticed takes a bit longer to run than the fits performed\n",
        "in previous tutorials. This is because the dimensionality of the model we are fitted increased from 3 to 6.\n",
        "\n",
        "With the `CollectionPriorModel`, **PyAutoFit** provides all the tools needed to compose and fit any model imaginable!\n",
        "Lets fit a model composed of two `Gaussian`. and and an `Exponential`, which will have a dimensionality of N=9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_1 import gaussian_x2_exponential_x1\n",
        "\n",
        "dataset = htf.Dataset(\n",
        "    data=gaussian_x2_exponential_x1.data, noise_map=gaussian_x2_exponential_x1.noise_map\n",
        ")\n",
        "\n",
        "phase = htf.Phase(\n",
        "    phase_name=\"phase_t6_gaussian_x2_exponential_x1\",\n",
        "    profiles=af.CollectionPriorModel(\n",
        "        gaussian_0=htf.profiles.Gaussian,\n",
        "        gaussian_1=htf.profiles.Gaussian,\n",
        "        exponential=htf.profiles.Exponential,\n",
        "    ),\n",
        "    search=af.Emcee(),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x2_exponential_x1\"\n",
        "    \" folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can fully customize the model that we fit. Lets suppose we have a `Dataset` that consists of three `Gaussian` \n",
        "profiles, but we also know the following information about the dataset:\n",
        "\n",
        "- All 3 `Gaussian`.s are centrally aligned.\n",
        "- The `sigma` of one `Gaussian` is equal to 1.0.\n",
        "\n",
        "We can edit our `CollectionPriorModel` to meet these constraints accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian_0=htf.profiles.Gaussian,\n",
        "    gaussian_1=htf.profiles.Gaussian,\n",
        "    gaussian_2=htf.profiles.Gaussian,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This aligns the `centre`'s of the 3 `Gaussian`., reducing the dimensionality of the model from N=9 to N=7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian_0.centre = model.gaussian_1.centre\n",
        "model.gaussian_1.centre = model.gaussian_2.centre"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This fixes the `sigma` value of one `Gaussian` to 1.0, further reducing the dimensionality from N=7 to N=6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian_0.sigma = 1.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now fit this model using a `Phase` as per usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_1 import gaussian_x3\n",
        "\n",
        "dataset = htf.Dataset(data=gaussian_x3.data, noise_map=gaussian_x3.noise_map)\n",
        "\n",
        "phase = htf.Phase(phase_name=\"phase_t6_gaussian_x3\", profiles=model, search=af.Emcee())\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x3\"\n",
        "    \" folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with that, we are complete. In this tutorial, we learned how to compose complex models in **PyAutoFit** and adjust \n",
        "our `phase.py` and `analyis.py` modules to fit them. To end, you should think again in more detail about your model\n",
        "fitting problem:\n",
        "\n",
        "Are there many different model components you may wish to define and fit?\n",
        "\n",
        "Is your data the super position of many different model components, like the profiles in this tutorial?\n",
        "\n",
        "In this tutorial, all components of our model did the same thing, represent a 1D profile. In your model, you may\n",
        "have model components that represent different parts of your model, which need to be combined in more complicated ways\n",
        "in order to create your model-fit. In such circumstances, the `fit` method in your `Analysis` class may be \n",
        "significantly more complex than the example shown in this tutorial. Nevertheless, you now have all the tools you need \n",
        "to define, compose and fit very complex models, there isn't much left for you to learn on your journey through **PyAutoFit**!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}