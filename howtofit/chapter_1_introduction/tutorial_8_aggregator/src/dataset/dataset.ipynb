{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "\n",
        "# The 'dataset.py' module has been extended to give the dataset a name and metadata.\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data, noise_map, name=None):\n",
        "        \"\"\"A class containing the data and noise-map of a 1D line dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : np.ndarray\n",
        "            The array of the data, in arbitrary units.\n",
        "        noise_map : np.ndarray\n",
        "            An array describing the RMS standard deviation error in each data pixel, in arbitrary units.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.noise_map = noise_map\n",
        "\n",
        "        # The name of the dataset is used by the aggregator, to determine the name of the file the dataset is saved as\n",
        "        # and so that when using the aggregator you can know which dataset you are manipulating.\n",
        "\n",
        "        self.name = name if name is str else \"dataset\"\n",
        "\n",
        "    @property\n",
        "    def xvalues(self):\n",
        "        return np.arange(self.data.shape[0])\n",
        "\n",
        "    @classmethod\n",
        "    def from_fits(cls, data_path, noise_map_path, name=None):\n",
        "        \"\"\"Load the data and noise-map of a 1D line dataset from '.fits' files.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_path : str\n",
        "            The path on your hard-disk to the '.fits' file of the data.\n",
        "        noise_map_path : str\n",
        "            The path on your hard-disk to the '.fits' file of the noise-map.\n",
        "        \"\"\"\n",
        "        data_hdu_list = fits.open(data_path)\n",
        "        noise_map_hdu_list = fits.open(noise_map_path)\n",
        "\n",
        "        data = np.array(data_hdu_list[0].data)\n",
        "        noise_map = np.array(noise_map_hdu_list[0].data)\n",
        "\n",
        "        return Dataset(data=data, noise_map=noise_map, name=name)\n",
        "\n",
        "\n",
        "class MaskedDataset:\n",
        "    def __init__(self, dataset, mask):\n",
        "        \"\"\"\n",
        "        A masked dataset, which is an image, noise-map and mask.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: im.Dataset\n",
        "            The dataset (the image, noise-map, etc.)\n",
        "        mask: msk.Mask\n",
        "            The 1D mask that is applied to the dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.mask = mask\n",
        "        self.data = dataset.data * np.invert(mask)\n",
        "        self.noise_map = dataset.noise_map * np.invert(mask)\n",
        "\n",
        "    @property\n",
        "    def xvalues(self):\n",
        "        return np.arange(self.data.shape[0])\n",
        "\n",
        "    def signal_to_noise_map(self):\n",
        "        return self.data / self.noise_map\n",
        "\n",
        "    def with_left_trimmed(self, data_trim_left):\n",
        "\n",
        "        if data_trim_left is None:\n",
        "            return self\n",
        "\n",
        "        # Here, we use the existing masked dataset to create a trimmed dataset.\n",
        "\n",
        "        data_trimmed = self.dataset.data[data_trim_left:]\n",
        "        noise_map_trimmed = self.dataset.noise_map[data_trim_left:]\n",
        "\n",
        "        dataset_trimmed = Dataset(data=data_trimmed, noise_map=noise_map_trimmed)\n",
        "\n",
        "        mask_trimmed = self.mask[data_trim_left:]\n",
        "\n",
        "        return MaskedDataset(dataset=dataset_trimmed, mask=mask_trimmed)\n",
        "\n",
        "    def with_right_trimmed(self, data_trim_right):\n",
        "\n",
        "        if data_trim_right is None:\n",
        "            return self\n",
        "\n",
        "        # We do the same as above, but removing data to the right.\n",
        "\n",
        "        data_trimmed = self.dataset.data[:-data_trim_right]\n",
        "        noise_map_trimmed = self.dataset.noise_map[:-data_trim_right]\n",
        "\n",
        "        dataset_trimmed = Dataset(data=data_trimmed, noise_map=noise_map_trimmed)\n",
        "\n",
        "        mask_trimmed = self.mask[:-data_trim_right]\n",
        "\n",
        "        return MaskedDataset(dataset=dataset_trimmed, mask=mask_trimmed)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}